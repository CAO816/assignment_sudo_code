{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31154,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install transformers==4.44.2","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:01:08.443673Z","iopub.execute_input":"2025-10-21T10:01:08.444354Z","iopub.status.idle":"2025-10-21T10:01:08.448240Z","shell.execute_reply.started":"2025-10-21T10:01:08.444328Z","shell.execute_reply":"2025-10-21T10:01:08.447422Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"!git clone https://github.com/qhungngo/EVBCorpus.git","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:01:08.450344Z","iopub.execute_input":"2025-10-21T10:01:08.450618Z","iopub.status.idle":"2025-10-21T10:01:08.581281Z","shell.execute_reply.started":"2025-10-21T10:01:08.450597Z","shell.execute_reply":"2025-10-21T10:01:08.580407Z"}},"outputs":[{"name":"stdout","text":"fatal: destination path 'EVBCorpus' already exists and is not an empty directory.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"!pip install rarfile","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:01:08.582820Z","iopub.execute_input":"2025-10-21T10:01:08.583125Z","iopub.status.idle":"2025-10-21T10:01:11.634409Z","shell.execute_reply.started":"2025-10-21T10:01:08.583104Z","shell.execute_reply":"2025-10-21T10:01:11.633681Z"}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: rarfile in /usr/local/lib/python3.11/dist-packages (4.2)\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"import re\nimport rarfile\nimport os\nimport unicodedata\nfrom transformers import MarianTokenizer, MarianMTModel, Trainer, TrainingArguments\nfrom datasets import Dataset","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:01:11.635404Z","iopub.execute_input":"2025-10-21T10:01:11.635726Z","iopub.status.idle":"2025-10-21T10:01:18.707538Z","shell.execute_reply.started":"2025-10-21T10:01:11.635687Z","shell.execute_reply":"2025-10-21T10:01:18.707003Z"}},"outputs":[{"name":"stderr","text":"2025-10-21 10:01:14.551491: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1761040874.573717    2203 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1761040874.580524    2203 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"rar_path = \"/kaggle/working/EVBCorpus/EVBCorpus_EVBNews_v2.0.rar\"\nextract_dir = \"/kaggle/working/data\"\n\n# Tạo thư mục đích nếu chưa có\nos.makedirs(extract_dir, exist_ok=True)\n\n# Mở và giải nén\nwith rarfile.RarFile(rar_path) as rf:\n    rf.extractall(path=extract_dir)\n\nprint(\"✅ Giải nén thành công!\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:01:18.709457Z","iopub.execute_input":"2025-10-21T10:01:18.710091Z","iopub.status.idle":"2025-10-21T10:01:22.093761Z","shell.execute_reply.started":"2025-10-21T10:01:18.710071Z","shell.execute_reply":"2025-10-21T10:01:22.093106Z"}},"outputs":[{"name":"stdout","text":"✅ Giải nén thành công!\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"# import shutil\n# shutil.rmtree('/kaggle/working/data/EVBCorpus_v1')\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:01:22.094430Z","iopub.execute_input":"2025-10-21T10:01:22.094633Z","iopub.status.idle":"2025-10-21T10:01:22.097729Z","shell.execute_reply.started":"2025-10-21T10:01:22.094616Z","shell.execute_reply":"2025-10-21T10:01:22.097066Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"import os\nfrom bs4 import BeautifulSoup\n\n# Đường dẫn tới thư mục chứa các file SGML\ndata_dir = \"/kaggle/working/data\"\n\n# Lưu các bài báo\narticles = []\n\n# Duyệt qua tất cả file .sgml\nfor filename in sorted(os.listdir(data_dir)):\n    if filename.endswith(\".sgml\"):\n        file_path = os.path.join(data_dir, filename)\n        with open(file_path, \"r\", encoding=\"utf-8\", errors=\"ignore\") as f:\n            content = f.read()\n            soup = BeautifulSoup(content, \"html.parser\")\n\n            # Tùy cấu trúc file, có thể là <DOC> hoặc <TEXT>\n            for doc in soup.find_all(\"doc\"):\n                docno = doc.find(\"docno\").get_text(strip=True) if doc.find(\"docno\") else None\n                text = doc.find(\"text\").get_text(strip=True) if doc.find(\"text\") else None\n\n                if text:\n                    articles.append({\"id\": docno or filename, \"text\": text})\n\nprint(f\"Đã đọc {len(articles)} bài báo.\")\nprint(articles[0])  # xem thử 1 mẫu\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:01:22.098539Z","iopub.execute_input":"2025-10-21T10:01:22.098782Z","iopub.status.idle":"2025-10-21T10:01:30.910561Z","shell.execute_reply.started":"2025-10-21T10:01:22.098742Z","shell.execute_reply":"2025-10-21T10:01:30.909749Z"}},"outputs":[{"name":"stdout","text":"Đã đọc 1000 bài báo.\n{'id': 'N0001.sgml', 'text': 'What is a Fenqing ?Fenqing là gì ?1-3;2-2;4-1;Fenqing is a Chinese word which literally means \" angry youth \" .Fenqing là một từ tiếng Hoa mà nghĩa đen là \" thanh niên phẫn nộ \" .1-1;2-2;3-3;4-5,6;5-4;6-7;7-8,9;8-10;10-14,15;11-12,13;This word has many translations in English such as cynical youth , young nationalists , hysterical youth and angry young men .Từ này có nhiều cách dịch sang tiếng Anh như là thanh niên hoài nghi , thanh niên theo chủ nghĩa dân tộc , thanh niên cuồng loạn và thanh niên tức giận .1-2;2-1;3-3;4-4;5-5,6;6-7;7-8,9;8-10,11;10-14,15;11-12,13;13-17,18;14-20,21,22,23;16-27,28;17-25,26;18-29;19-32,33;20-30,31;I personally like to call them mob youth or ignorant angry youth .Cá nhân tôi thích gọi chúng là bọn thanh niên du thủ du thực hoặc thanh niên phẫn nộ và ngu dốt .1-3;2-1,2;3-4;5-5;6-6;7-11,12,13,14;8-9,10;9-15;10-21,22;11-18,19;12-16,17;It is impossible to understand China without knowing what Fenqing is and what role they play in the society in today \\'s China .Không thể hiểu được Trung Quốc nếu không biết Fenqing là gì và họ đóng vai trò gì trong xã hội Trung Quốc ngày nay .3-1,2;5-3,4;6-5,6;7-8;8-9;9-12;10-10;11-11;12-13;13-18;14-16,17;15-14;16-15;17-19;19-20,21;21-24,25;23-22,23;I will try to paint a portrait of a Fenqing in this post .Trong bài viết này , tôi sẽ cố phác hoạ chân dung một Fenqing .1-6;2-7;3-8;5-9,10;7-11,12;9-13;10-14;11-1;12-4;13-2,3;What a Fenqing is like ?Fenqing là người như thế nào ?3-1;4-2;5-4,5,6;Fenqing is someone who is usually below twenty years of age , though sometimes people who are at their twenties or older can also be identified as Fenqing .Thường thì Fenqing là người dưới hai mươi tuổi , tuy đôi lúc có những kẻ hơn hai mươi tuổi cũng được coi là Fenqing .1-3;2-2;4-5;5-4;6-1;7-6;8-7,8;9,10,11-9;13-11;14-12,13;16-15,16;20-18,19;22-17;23-21,22;26-23,24;28-25;Though you can find the majority of Fenqing among high school and college students , age is not the most important feature .Tuy bạn có thể thấy đa số các Fenqing trong số học sinh trung học và sinh viên cao đẳng , nhưng tuổi tác không phải là đặc điểm quan trọng nhất .1-1;2-2;3-3,4;4-5;6-6,7;8-9;9-10,11;10,11-14,15;12-16;13-19,20;14-17,18;16-23,24;17-27;18-25,26;20-32;21-30,31;22-28,29;What really matters is their outlook of China and the world .Điều thực sự quan trọng là cách họ nhìn nhận về Trung Quốc và thế giới .1-1;2-2,3;3-4,5;4-6;5-8;6-9,10;7-11;8-12,13;9-14;11-15,16;What a Fenqing does n\\'t know ?Fenqing không biết những gì ?1-4,5;3-1;5-2;6-3;The fact that most Fenqing are ignorant of many things determines their opinions and views of the world and China .Việc mà đa số Fenqing không hiểu biết nhiều thứ là yếu tố để xác định ý kiến và quan điểm của họ về thế giới và Trung Quốc .2-1;3-2;4-3,4;5-5;7-6,7,8;9-9;10-10;11-15,16;12-22,23;13-17,18;14-19;15-20,21;16-24;18-25,26;19-27;20-28,29;A typical Fenqing does not know the answer to the following questions :Một Fenqing tiêu biểu không biết trả lời những câu hỏi sau :1-1;2-3,4;3-2;5-5;6-6;8-7,8;11-12;12-9,10,11;What are the differences between the nation , the government and the party ?Đâu là sự khác biệt giữa quốc gia , chính phủ và đảng ?1-1;2-2;4-3,4,5;5-6;7-7,8;10-10,11;11-12;13-13;Fenqing believe these three things are basically the same thing .Fenqing tin rằng ba thứ này về cơ bản là giống nhau .1-1;2-2,3;3-6;4-4;5-5;7-7,8,9;9-11,12;How large is the China \\'s territory and what is the ranking of its land area ?Lãnh thổ Trung Quốc rộng bao nhiêu và diện tích đất của nó đứng hàng thứ mấy ?1-6,7;2-5;5-3,4;7-1,2;8-8;9-17;12-15,16;14-12,13;15-11;16-9,10;Fenqing were taught that China was the third largest country in the world , and they never knew it shrank a little .Fenqing được dạy dỗ rằng Trung Quốc là quốc gia lớn thứ ba trên thế giới , và họ không bao giờ biết rằng nó đã thu hẹp chút ít .1-1;3-2,3,4;4-5;5-6,7;6-8;8-12,13;9-11;10-9,10;11-14;13-15,16;15-18;16-19;17-20,21,22;18-23;19-25;20-26,27,28;22-29,30;What is a purpose of economic and social development ?Đâu là mục đích của việc phát triển kinh tế và xã hội ?1-1;2-2;4-3,4;5-5;6-9,10;7-11;8-12,13;9-6,7,8;Fenqing believe everything can be readily sacrificed to achieve \" the grand goal \" .Fenqing tin rằng có thể sẵn sàng hy sinh mọi thứ để đạt được \" mục tiêu vĩ đại \" .1-1;2-2,3;3-10,11;4-4,5;6-6,7;7-8,9;8-12;9-13,14;12-18,19;13-16,17;For them , the value of human life and dignity is readily expendable for the slogans and ideologies .Đối với họ , có thể hy sinh dễ dàng giá trị của đời người và nhân phẩm vì những câu khẩu hiệu và ý thức hệ .1-1,2;2-3;5-11,12;6-13;7-15;8-14;9-16;10-17,18;12-9,10;13-5,6,7,8;14-19;16-20,21,22,23;17-24;18-25,26,27;How the tax money is spent ?Tiền thuế được sử dụng như thế nào ?1-6,7,8;3-2;4-1;6-3,4,5;Fenqing do know or care they are in fact tax payers and has a right to know how their tax money is spent .Fenqing vốn biết rõ hoặc quan tâm mình thực sự là người đóng thuế và có quyền biết tiền thuế của họ được sử dụng như thế nào .1-1;3-3,4;4-5;5-6,7;6-8;7-11;9-9,10;10-14;11-12,13;12-15;13-16;15-17;17-18;18-26,27,28;19-21,22;20-20;21-19;23-23,24,25;What is Fenqing \\'s outlook ?Quan điểm của Fenqing là gì ?1-5,6;3-4;4-3;5-1,2;Their ignorance and lack of social experience shaped their outlook :Sự kém hiểu biết và thiếu kinh nghiệm sống của họ đã định hình cho quan điểm của họ :1-10,11;2-1,2,3,4;3-5;4-6;6-9;7-7,8;8-12,13,14;9-18,19;10-16,17;U.S. is a monolith .Hoa Kỳ là một khối thống nhất .1-1,2;2-3;3-4;4-5,6,7;America is bad , bad and bad because Bush is bad .Mỹ xấu , xấu và xấu vì Bush xấu .1-1;3-2;5-4;6-5;7-6;8-7;9-8;11-9;Anti-Japan and call for boycotting Japanese products while enjoying Japanese AV or cartoons .Chống Nhật Bản và kêu gọi tẩy chay hàng Nhật Bản trong khi vẫn thích xem phim sex và phim hoạt hình Nhật Bản .1-1,2,3;2-4;3-5,6;5-7,8;6-10,11;7-9;8-12,13;9-15,16;10-23,24;11-17,18;12-19;13-20,21,22;China \\'s stock market slumps because of the conspiracy of the imperialist western countries .Thị trường chứng khoán Trung Quốc sa sút là vì âm mưu của đế quốc phương tây .1-5,6;3-3,4;4-1,2;5-7,8;6-10;9-11,12;10-13;13-16,17;14-14,15;The price of housing in China skyrocketed because of the hot money of the international speculators .Giá nhà ở Trung quốc tăng vọt là vì các khoản đầu tư ngắn hạn của giới đầu cơ quốc tế .2-1;4-2;5-3;6-4,5;7-6,7;8-8,9;11-14,15;12-10,11,12,13;13-16;15-20,21;16-17,18,19;Western countries led by the U.S. are trying to encircle and contain China .Các quốc gia phương Tây do Mỹ cầm đầu đang cố bao vây và kìm hãm Trung Quốc .1-4,5;2-1,2,3;3-8,9;4-6;6-7;8-10,11;10-12,13;11-14;12-15,16;13-17,18;The Internet should be censured and any bad information , like the flies or mosquitoes outside the room , must be screened and filtered .Mạng Internet nên được kiểm duyệt và mọi thông tin xấu , giống ruồi muỗi bên ngoài phòng , phải được sàng lọc .2-1,2;3-3;5-4,5,6;6-7;7-8;8-11;9-9,10;11-13;13-14;15-15;16-16,17;18-18;20-20;22-21,22;24-23;CNN is evil because CNN lied , but it is fine for CCTV to modify the information to maintain the stability of the society .CNN xấu vì CNN nói láo , nhưng CCTV điều chỉnh thông tin để duy trì ổn định xã hội thì không sao .1-1;3-2;4-3;5-4;6-5,6;8-8;10-21;11-22,23;13-9;15-10,11;17-12,13;18-14;19-15,16;21-17,18;24-19,20;What is the role of Fenqing in China ?Vai trò của Fenqing ở Trung quốc là gì ?1-9;2-8;4-1,2;5-3;6-4;7-5;8-6,7;Fenqing are often spontaneous , but it is easy to fan up their blind fervency - just tell them China has been attacked .Fenqing thường là tự phát , nhưng dễ thổi bùng cái thói cuồng nhiệt mù quáng của họ - chỉ cần bảo với họ là Trung Quốc đã bị tấn công .1-1;2-3;3-2;4-4,5;6-7;9-8;11-9,10;13-17,18;14-15,16;15-11,12,13,14;17-20,21;18-22;19-24;20-26,27;23-28,29,30,31;Fenqing never realized that they are manipulated and they are among the first to be expended for the \" greater good \" .Fenqing không bao giờ nhận ra rằng họ bị điều khiển và họ nằm trong số những kẻ đầu tiên bị hy sinh vì \" đại nghĩa \" .1-1;2-2,3,4;3-5,6;4-7;5-8;7-9,10,11;8-12;9-13;10-14;11-15,16;13-17,18,19,20;16-21,22,23;17-24;20-26;21-27;Their anger is harnessed and channeled to the designated objects , yet they are carefully guarded not to cross the line and overdo job .Cơn phẫn nộ của họ bị khai thác và hướng đến các mục tiêu định sẵn , thế nhưng họ vẫn bị kiểm soát kỹ lưỡng để khỏi vượt quá giới hạn và hành động thái quá .1-4,5;2-1,2,3;4-6,7,8;5-9;6-10;7-11;9-15,16;10-12,13,14;12-18,19;13-20;15-25,26;16-22,23,24;17-28;18-27;19-29,30,31,32;22-33;23-36,37;24-34,35;Fenqing are not patriotsFenqing không phải là những người yêu nước1-1;2-4;3-2,3;4-5,6,7,8;China is the longest continuation of a civilization , and for centuries , it was leading the world by its economic development and technological inventions .Trung Quốc là phần nối dài nhất của một nền văn minh , và trong nhiều thế kỷ , nó đã đứng đầu thế giới do các thành tựu kinh tế và phát minh kỹ thuật của họ .1-1,2;2-3;4-6,7;5-4,5;6-8;7-9;8-10,11,12;10-14;11-15;12-16,17,18;14-20;16-21,22,23;18-24,25;19-26;20-37,38;21-30,31;22-27,28,29;23-32;24-35,36;25-33,34;The enormous suffering and humiliation over a century deeply hurt Chinese people .Nỗi thống khổ và tủi nhục vô biên trong hơn một thế kỷ đã làm người dân Trung Quốc bị tổn thương sâu sắc .2-7,8;3-1,2,3;4-4;5-5,6;6-10;7-11;8-12,13;9-23,24;10-21,22;11-18,19;12-16,17;It became a national dream of China to drive out the western invaders and colonizers and stand tall in the world again with dignity and glory .Nó đã trở thành giấc mơ của dân tộc Trung Quốc việc đánh đuổi quân xâm lược và thực dân phương tây , và lại vươn lên trên thế giới một cách vinh quang và đường hoàng .1-1;2-2,3,4;4-8,9;5-5,6;6-7;7-10,11;9-12,13,14;12-21,22;13-15,16,17;14-18;15-19,20;16-24;17,18-25,26,27;19-28;21-29,30;24-31,32,33,34;25-35;26-36,37;Undeniably , this is the root of Chinese patriotism and nationalism .Rõ ràng đây là cội nguồn của lòng yêu nước và chủ nghĩa dân tộc của Trung Hoa .1-1,2;3-3;4-4;6-5,6;7-7;8-17,18;9-8,9,10;10-11;11-12,13,14,15;In a justified hostility toward the past western colonizers and invaders ( especially Japanese ) , Fenqing are a group people who turn a blind eye to the domestic problems or simply attribute everything bad to the imperialists .Do hận thù có căn cơ đối với thực dân phương tây và quân xâm lược trong quá khứ ( nhất là Nhật Bản ) , Fenqing là một nhóm người vờ không thấy những vấn đề trong nước hoặc chỉ cần đổ thừa mọi thứ xấu xa cho bọn đế quốc .3-1;4-2,3;5-7,8;7-17,18,19;8-11,12;9-9,10;10-13;11-14,15,16;13-21,22;14-23,24;17-27;18-28;19-29;20-30;21-31;23-32;25,26-33,34;29-38,39;30-35,36,37;31-40;32-41,42;33-43,44;34-45,46;35-47,48;36-49;38-50,51,52;They are conveniently absent when shoddy buildings collapsed , when farmers are displaced and the Internet is turning into a GLAN ( the Great Local Area Network ) .Họ vắng mặt đúng lúc mà các toà nhà kém chất lượng đổ sập , nông dân bị di dời và mạng internet đang trở thành GLAN ( mạng cục bộ khổng lồ ) .1-1;4-2,3;5-4,5;6-10,11,12;7-7,8,9;8-13,14;11-16,17;13-18,19,20;14-21;16-22,23;17-24;18-25,26;21-27;24-32,33;25,26-30,31;27-29;Fenqing are not qualified to be called patriots for the simple reason they are ignorant of three simple political concepts I mentioned above .Fenqing không đủ tiêu chuẩn để được gọi là người yêu nước vì lý do đơn giản là họ không biết ba khái niệm chính trị đơn giản mà tôi đã đề cập ở trên .1-1;3-2,3;4-4,5;5-6;7-7,8,9;8-10,11,12;9-13;11-16,17;12-14,15;13-19;15-20,21;17-22;18-27,28;19-25,26;20-23,24;21-30;22-31,32,33;23-34,35;They are party-triots .Họ là những người yêu đảng .1-1;2-2;3-3,4,5,6;Who produced Fenqing ?Ai đã tạo ra Fenqing ?1-1;2-2,3,4;3-5;When I played a movie about the war in Iraq - No End in Sight - to a group of young college students , a student came up to me and said :Khi tôi chiếu một bộ phim về chiến tranh ở Iraq - No End in Sight - cho một nhóm sinh viên cao đẳng , một sinh viên đã đến chỗ tôi và nói :1-1;2-2;3-3;4-4;5-5,6;6-7;8-8,9;9-10;10-11;12-13;13-14;14-15;15-16;17-18;18-19;19-20;22-23,24;23-21,22;25-26;26-27,28;27-29,30;30-32;31-33;32-34;\" Our teacher of Mideast history told us Saddam was a national hero of Iraq , and people lived a prosperous and a happy life under his regime . \"\" Giáo viên dạy lịch sử Trung Đông của chúng tôi đã nói với chúng tôi rằng Saddam là vị anh hùng dân tộc của Iraq , và người dân đã sống thịnh vượng và hạnh phúc dưới chế độ của ông ấy . \"2-9,10,11;3-2,3;5-7,8;6-5,6;7-12,13;8-15,16;9-18;10-19;12-23,24;13-20,21,22;14-25;15-26;17-28;18-29,30;19-31,32;21-33,34;22-35;24-36,37;26-38;27-41,42,43;28-39,40;I was surprised to hear what she said , and told her what Saddam did to Kurdish population in northern Iraq and the fact that he was once supported by the U.S. government during Iran-Iraq War .Tôi ngạc nhiên khi nghe những điều cô ấy nói , và kể cho cô ấy nghe những chuyện Saddam đã làm đối với người Kurd ở miền bắc Iraq và chuyện ông ta từng được chính phủ Hoa Kỳ hỗ trợ trong cuộc chiến Iran-Iraq .1-1;3-2,3;5-5;6-6,7;7-8,9;8-10;10-12;11-13,14;12-15,16;13-18,19;14-20;15-21,22;16-23,24;17-25,26;19-27;20-28,29;21-30;22-31;25-32;26-33,34;29-35,36,41,42;32-39,40;33-37,38;34-43;35-46;36-44,45;Will Fenqing remain to be Fenqing forever ?Liệu Fenqing có mãi mãi là Fenqing không ?1-1;2-2;3-3;5-6;6-7;7-4,5;We had a 3/4 week of itChúng ta đã có 3/4 tuần1-1,2;2-3,4;4-5;5-6;'}\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"def extract_sentence_pairs(text):\n    # Tách theo dấu chấm câu và căn chỉnh\n    text = re.sub(r'([\\d,]+)-([\\d,]+);', '', text)\n    parts = re.split(r'(?<=[\\.\\?\\!])', text)\n    parts = [p.strip() for p in parts if p.strip()]\n\n    src, tgt = [], []\n    for i in range(0, len(parts), 2):\n        if i + 1 < len(parts):\n            en = parts[i]\n            vi = parts[i + 1]\n            # Bỏ qua dòng căn chỉnh (phần thứ 2 sau tiếng Việt)\n            if re.search(r'[A-Za-z]', en) and re.search(r'[À-ỹ]', vi):\n                src.append(en)\n                tgt.append(vi)\n    return src, tgt\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:01:30.911423Z","iopub.execute_input":"2025-10-21T10:01:30.912080Z","iopub.status.idle":"2025-10-21T10:01:30.918027Z","shell.execute_reply.started":"2025-10-21T10:01:30.912056Z","shell.execute_reply":"2025-10-21T10:01:30.917219Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"def normalize_text(s):\n    s = unicodedata.normalize('NFC', s)\n    s = re.sub(r'\\s+', ' ', s).strip()\n    return s","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:01:30.918833Z","iopub.execute_input":"2025-10-21T10:01:30.919074Z","iopub.status.idle":"2025-10-21T10:01:30.932504Z","shell.execute_reply.started":"2025-10-21T10:01:30.919057Z","shell.execute_reply":"2025-10-21T10:01:30.931811Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"sources, targets = [], []\nfor article in articles:\n    src, tgt = extract_sentence_pairs(article['text'])\n    sources.extend([normalize_text(s) for s in src])\n    targets.extend([normalize_text(t) for t in tgt])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:01:30.933184Z","iopub.execute_input":"2025-10-21T10:01:30.933380Z","iopub.status.idle":"2025-10-21T10:01:32.154524Z","shell.execute_reply.started":"2025-10-21T10:01:30.933365Z","shell.execute_reply":"2025-10-21T10:01:32.153979Z"}},"outputs":[],"execution_count":10},{"cell_type":"code","source":"data = {\"translation\": [{\"en\": s, \"vi\": t} for s, t in zip(sources, targets)]}\ndataset = Dataset.from_dict(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:01:32.156145Z","iopub.execute_input":"2025-10-21T10:01:32.156407Z","iopub.status.idle":"2025-10-21T10:01:32.297235Z","shell.execute_reply.started":"2025-10-21T10:01:32.156392Z","shell.execute_reply":"2025-10-21T10:01:32.296623Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"# Load mô hình pretrained\nmodel_name = \"Helsinki-NLP/opus-mt-en-vi\"\ntokenizer = MarianTokenizer.from_pretrained(model_name, trust_remote_code=True)\nmodel = MarianMTModel.from_pretrained(model_name, trust_remote_code=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:01:32.297933Z","iopub.execute_input":"2025-10-21T10:01:32.298110Z","iopub.status.idle":"2025-10-21T10:01:37.015164Z","shell.execute_reply.started":"2025-10-21T10:01:32.298096Z","shell.execute_reply":"2025-10-21T10:01:37.014366Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"source.spm:   0%|          | 0.00/809k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d3db07f1dcfc446781b3ac5285d11b21"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"target.spm:   0%|          | 0.00/756k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"753c28c68f884a4ca3ae51d515021cb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3625bf8068ed4f64b0f12463605a2d82"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"737b1aeb82d242099373f301c50a581f"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/models/marian/tokenization_marian.py:175: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\nThe argument `trust_remote_code` is to be used with Auto classes. It has no effect here and is ignored.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/289M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9d832e04291b40a599f6560e7816bbe5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/293 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4c5eeb55426841b5a94e71325c561b84"}},"metadata":{}}],"execution_count":12},{"cell_type":"code","source":"def preprocess_function(batch):\n    inputs = [ex[\"en\"] for ex in batch[\"translation\"]]\n    targets = [ex[\"vi\"] for ex in batch[\"translation\"]]\n\n    model_inputs = tokenizer(inputs, max_length=128, truncation=True, padding=\"max_length\")\n\n    with tokenizer.as_target_tokenizer():\n        labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\")\n\n    model_inputs[\"labels\"] = labels[\"input_ids\"]\n    return model_inputs\n\ntokenized_dataset = dataset.map(preprocess_function, batched=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:04:04.503435Z","iopub.execute_input":"2025-10-21T10:04:04.503737Z","iopub.status.idle":"2025-10-21T10:04:12.566907Z","shell.execute_reply.started":"2025-10-21T10:04:04.503717Z","shell.execute_reply":"2025-10-21T10:04:12.566313Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/27581 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"40ebb61ca40543afb39d5295dadfe444"}},"metadata":{}},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py:4126: UserWarning: `as_target_tokenizer` is deprecated and will be removed in v5 of Transformers. You can tokenize your labels by using the argument `text_target` of the regular `__call__` method (either in the same call as your input texts if you use the same keyword arguments, or in a separate call.\n  warnings.warn(\n","output_type":"stream"}],"execution_count":14},{"cell_type":"code","source":"args = TrainingArguments(\n    output_dir=\"./results\",\n    logging_strategy=\"steps\",\n    logging_steps=50,             # tần suất log\n    save_strategy=\"steps\",        # lưu checkpoint định kỳ\n    save_steps=500,\n    per_device_train_batch_size=8,\n    num_train_epochs=3,\n    learning_rate=2e-5,\n    save_total_limit=1,\n    logging_dir=\"./logs\",\n    report_to=\"none\"\n)\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=tokenized_dataset\n)\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:23:07.854487Z","iopub.execute_input":"2025-10-21T10:23:07.854837Z","iopub.status.idle":"2025-10-21T10:27:49.494534Z","shell.execute_reply.started":"2025-10-21T10:23:07.854815Z","shell.execute_reply":"2025-10-21T10:27:49.493447Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1081' max='5172' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1081/5172 04:40 < 17:43, 3.85 it/s, Epoch 0.63/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>50</td>\n      <td>0.647500</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.629400</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.610700</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.579700</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.615200</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.628600</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.656500</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.615900</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.594800</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.571000</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.579300</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.541000</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.594800</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.579000</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.623100</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.572300</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.609700</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.564300</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.570600</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.608900</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.558100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"Some non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[53684]], 'forced_eos_token_id': 0}\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\nSome non-default generation parameters are set in the model config. These should go into a GenerationConfig file (https://huggingface.co/docs/transformers/generation_strategies#save-a-custom-decoding-strategy-with-your-model) instead. This warning will be raised to an exception in v4.41.\nNon-default generation parameters: {'max_length': 512, 'num_beams': 4, 'bad_words_ids': [[53684]], 'forced_eos_token_id': 0}\n/usr/local/lib/python3.11/dist-packages/torch/nn/parallel/_functions.py:70: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn(\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipykernel_2203/1498280401.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mtrain_dataset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtokenized_dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m )\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1936\u001b[0m                 \u001b[0mhf_hub_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable_progress_bars\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1937\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1938\u001b[0;31m             return inner_training_loop(\n\u001b[0m\u001b[1;32m   1939\u001b[0m                 \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1940\u001b[0m                 \u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mresume_from_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2282\u001b[0m                     \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging_nan_inf_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2283\u001b[0m                     \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_torch_xla_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2284\u001b[0;31m                     \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2285\u001b[0m                 ):\n\u001b[1;32m   2286\u001b[0m                     \u001b[0;31m# if loss is nan or inf simply add the average of previous logged losses\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":17},{"cell_type":"code","source":"text = [\"With all sincerity, I wish you will be happy.\"]\ninputs = tokenizer(text, return_tensors=\"pt\", padding=True).to(\"cuda\")\ntranslated = model.generate(**inputs)\nprint(tokenizer.decode(translated[0], skip_special_tokens=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-21T10:32:18.450336Z","iopub.execute_input":"2025-10-21T10:32:18.450587Z","iopub.status.idle":"2025-10-21T10:32:18.621708Z","shell.execute_reply.started":"2025-10-21T10:32:18.450569Z","shell.execute_reply":"2025-10-21T10:32:18.621009Z"}},"outputs":[{"name":"stdout","text":"Với tất cả sự thành thật, tôi ước gì bạn sẽ hạnh phúc.\n","output_type":"stream"}],"execution_count":28}]}